{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define filepaths\n",
    "workspace = \"/Users/advaysingh/Documents/projects/hindi_classification/\" \n",
    "#print(\"Current workspace:\", workspace) /Users/advaysingh/Documents/projects/hindi_classification/server/snapshot.png\n",
    "\n",
    "data = os.path.join(workspace, 'data/Hindi/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test dicts with files and labels\n",
    "\n",
    "def create_dict(x: str) -> dict:\n",
    "    x_dict = {}\n",
    "    i = 0\n",
    "    for dir in os.listdir(os.path.join(data, x)):\n",
    "        for file in os.listdir(os.path.join(data, x, dir)):\n",
    "            x_dict[os.path.join(data, x, dir, file)] = i\n",
    "        i += 1\n",
    "    return x_dict\n",
    "\n",
    "# make pandas df\n",
    "\n",
    "train_df = pd.DataFrame.from_dict(create_dict('Train'), orient='index')\n",
    "test_df = pd.DataFrame.from_dict(create_dict('Test'), orient='index')\n",
    "\n",
    "#print(train_df)\n",
    "#df_temp = train_df[0].drop_duplicates()\n",
    "# print(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09003057317038046, 0.24472847105479767, 0.6652409557748219]\n"
     ]
    }
   ],
   "source": [
    "# Activations class\n",
    "class Activation:\n",
    "    # can add more types\n",
    "    def __init__(self, act_type: str) -> None:\n",
    "        self.act = act_type\n",
    "\n",
    "    def print_act(self) -> None:\n",
    "        return self.act\n",
    "    \n",
    "    def compute(self, z) -> list:\n",
    "\n",
    "        # Sigmoid function\n",
    "        if (self.act == 'sigmoid'):\n",
    "            n = []\n",
    "            for val in (z):\n",
    "                n.append(1.0 / (1.0 + np.exp(val)))\n",
    "            return n\n",
    "        \n",
    "        # ReLU function\n",
    "        elif (self.act == 'relu'):\n",
    "            vals = []\n",
    "            for val in z:\n",
    "                if val < 0.0:\n",
    "                    vals.append(0.0)\n",
    "                else:\n",
    "                    vals.append(1.0)\n",
    "            return vals\n",
    "\n",
    "    def prime(self, z: list):\n",
    "\n",
    "        # Sigmoid prime\n",
    "        if (self.act == 'sigmoid'):\n",
    "            sigs = self.compute(z)\n",
    "            vals = []\n",
    "            for val in sigs:\n",
    "                vals.append(val * (1 - val))\n",
    "            return vals\n",
    "        \n",
    "        # ReLU prime\n",
    "        if (self.act == 'relu'):\n",
    "            vals = []\n",
    "            for val in z:\n",
    "                if val == 0:\n",
    "                    vals.append(0.0)\n",
    "                else:\n",
    "                    vals.append(1.0)\n",
    "            return vals\n",
    "\n",
    "\n",
    "def softmax(costs: list) -> list:\n",
    "    exp_vals = []\n",
    "    for cost in np.array(costs):\n",
    "        exp_vals.append(np.exp(cost))\n",
    "    return_vals = []\n",
    "    for i in range(len(exp_vals)):\n",
    "        return_vals.append(exp_vals[i] / sum(exp_vals))\n",
    "    return return_vals\n",
    "\n",
    "def softmax_prime(costs: list) -> list:\n",
    "    softs = softmax(costs)\n",
    "    vals = []\n",
    "    for val in softs:\n",
    "        vals.append(val * (1 - val))\n",
    "    return vals\n",
    "\n",
    "n = softmax([2, 3, 4])\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate(z: np.array) -> np.array:\n",
    "    \"\"\"Compute the sigmoid activation function.\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def act_prime(z: np.array) -> np.array:\n",
    "    \"\"\"Compute the derivative of the sigmoid activation function.\"\"\"\n",
    "    ap = activate(z)\n",
    "    return ap * (1 - ap)\n",
    "\n",
    "def softmax(z: np.array) -> np.array:\n",
    "    e_z = np.exp(z - np.max(z)) # Improved stability\n",
    "    return e_z / e_z.sum(axis=0)\n",
    "\n",
    "def softmax_prime(z: np.array) -> np.array:\n",
    "    softmax_vals = softmax(z)\n",
    "    # For each i, j in softmax output vector size: [si * (1 - si)] if i == j, otherwise: -si * sj\n",
    "    return softmax_vals * (1 - softmax_vals)\n",
    "    #return np.diag(softmax_vals) - np.outer(softmax_vals, softmax_vals)\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, layers: list, load_perams: bool) -> None:\n",
    "        self.train_df = train_df\n",
    "        self.layers = layers\n",
    "\n",
    "        self.all_weights = [None] * len(self.layers)\n",
    "        self.all_bias = [None] * len(self.layers)\n",
    "\n",
    "        # read in weights if load perams\n",
    "        if (load_perams):\n",
    "            layer = 0\n",
    "            weightlist = os.listdir(os.path.join(workspace, 'data', 'Hyper_p/Weights'))\n",
    "            for file in sorted(weightlist, key=lambda s: s.lower()):\n",
    "                self.all_weights[layer] = (pd.read_csv(os.path.join(workspace, 'data', 'Hyper_p/Weights', file)).to_numpy())\n",
    "                layer += 1\n",
    "            layer = 0\n",
    "            biaslist = os.listdir(os.path.join(workspace, 'data', 'Hyper_p/Biases'))\n",
    "            for file in sorted(biaslist, key=lambda s: s.lower()):\n",
    "                self.all_bias[layer] = (pd.read_csv(os.path.join(workspace, 'data', 'Hyper_p/Biases', file)).to_numpy())\n",
    "                layer += 1\n",
    "\n",
    "        else:\n",
    "            for i in range(len(layers)):\n",
    "                self.all_weights[i] = self.random_arrs(i)\n",
    "                if i == 0:\n",
    "                    self.all_bias[i] = np.random.uniform(low=-0.03125, high=0.03125, size=(self.layers[i],1))\n",
    "                else:\n",
    "                    bias_val = 0.5 # TODO reconsider\n",
    "                    self.all_bias[i] = np.random.uniform(low=-bias_val, high=bias_val, size=(self.layers[i],1))\n",
    "    \n",
    "\n",
    "    def random_arrs(self, layer: int):\n",
    "        if (layer == 0):\n",
    "            return(np.random.uniform(low=-0.03125, high=0.03125, size=(self.layers[layer],1024)))\n",
    "        else:\n",
    "            weight_val = 1 / math.sqrt(self.layers[layer - 1])\n",
    "            return(np.random.uniform(low=-weight_val, high=weight_val, size=(self.layers[layer], self.layers[layer-1])))\n",
    "\n",
    "    def img_to_np(self, dir) -> np.array:\n",
    "        return np.array(Image.open(dir)).flatten()\n",
    "    \n",
    "    def prop_forward(self, x: np.ndarray):\n",
    "        activations = [x] #activations.size > zs\n",
    "        zs = []\n",
    "        for i in range(len(self.layers)):\n",
    "            x = np.matmul(self.all_weights[i], x) + self.all_bias[i]\n",
    "            zs.append(x)\n",
    "            if (i == len(self.layers) - 1):\n",
    "                x = softmax(x)\n",
    "            else:\n",
    "                x = activate(x)\n",
    "            activations.append(x)\n",
    "        return activations, zs\n",
    "\n",
    "\n",
    "    \n",
    "    def prop_backward(self, x_batch: np.ndarray, y_batch: np.ndarray):\n",
    "        # Initialize gradients as zero\n",
    "        delta_b_sum = [np.zeros(b.shape) for b in self.all_bias]\n",
    "        delta_w_sum = [np.zeros(w.shape) for w in self.all_weights]\n",
    "\n",
    "        # Loop over each example in the batch\n",
    "        for x, y in zip(x_batch, y_batch):\n",
    "            activations, zs = self.prop_forward(x)\n",
    "            delta = (activations[-1] - y.reshape(46,1)) #* softmax_prime(zs[-1])\n",
    "\n",
    "            # Gradients for output layer\n",
    "            delta_b_sum[-1] += delta\n",
    "            delta_w_sum[-1] += np.dot(delta, activations[-2].transpose())\n",
    "\n",
    "            # Gradients for hidden layers\n",
    "            for i in range(2, len(self.layers)):\n",
    "                z = zs[-i]\n",
    "                sp = act_prime(z)\n",
    "                delta = np.dot(self.all_weights[-i + 1].transpose(), delta) * sp\n",
    "                delta_b_sum[-i] += delta\n",
    "                delta_w_sum[-i] += np.dot(delta, activations[-i - 1].T)\n",
    "\n",
    "        # Average the gradients over the mini-batch\n",
    "        num_examples = len(x_batch)\n",
    "        delta_b_avg = [db_sum / num_examples for db_sum in delta_b_sum]\n",
    "        delta_w_avg = [dw_sum / num_examples for dw_sum in delta_w_sum]\n",
    "\n",
    "        # Return the average gradients\n",
    "        return delta_w_avg, delta_b_avg\n",
    "    \n",
    "    def update_mini_batch(self, mini_batch, learning_rate):\n",
    "        # aggregate gradients from the mini_batch\n",
    "        delta_w, delta_b = self.prop_backward(mini_batch[0], mini_batch[1])\n",
    "    \n",
    "        # update weights and biases\n",
    "        self.all_weights = [w - (learning_rate * dw) for w, dw in zip(self.all_weights, delta_w)] # todo change\n",
    "        self.all_bias = [b - (learning_rate * db) for b, db in zip(self.all_bias, delta_b)] #todo change\n",
    "    \n",
    "\n",
    "    def train(self, X_train, y_train, epochs, learning_rate, mini_batch_size, test_df):\n",
    "        n = len(X_train)\n",
    "\n",
    "        # Convert to NumPy arrays if necessary\n",
    "        X_train_np = np.array(X_train) if not isinstance(X_train, np.ndarray) else X_train\n",
    "        y_train_np = np.array(y_train) if not isinstance(y_train, np.ndarray) else y_train\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            # Shuffle the training data for each epoch\n",
    "            permutation = np.random.permutation(n)\n",
    "            X_train_shuffled = X_train_np[permutation]\n",
    "            y_train_shuffled = y_train_np[permutation]\n",
    "        \n",
    "            # Partition training data into mini-batches\n",
    "            mini_batches = [\n",
    "                (X_train_shuffled[k:k+mini_batch_size], y_train_shuffled[k:k+mini_batch_size])\n",
    "                for k in range(0, n, mini_batch_size)\n",
    "            ]\n",
    "        \n",
    "            # Update the model's weights with each mini-batch\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, learning_rate)\n",
    "            \n",
    "            if(epoch % 10 == 0 and epoch != 0):\n",
    "                self.validate(test_df)\n",
    "\n",
    "            new_loss = self.calc_squared_loss(X_train, y_train)\n",
    "            print(f\"Epoch {epoch}, mean squared loss: {new_loss}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    def calc_squared_loss(self, X, y):\n",
    "        squared_errors = []\n",
    "        for i in range(len(X)):\n",
    "            y_pred, _ = self.prop_forward(X[i].reshape(1024, 1))  # prop_forward should give the prediction\n",
    "            squared_error = np.sum((y[i].reshape(46, 1) - y_pred[-1]) ** 2) / 2 \n",
    "            squared_errors.append(squared_error)\n",
    "        \n",
    "        # Calculate mean squared error over all examples.\n",
    "        mse = np.mean(squared_errors)\n",
    "        return mse\n",
    "\n",
    "    def pred(self, img: np.array):\n",
    "        img, _ = self.prop_forward(img)\n",
    "        #img, _ = self.prop_forward(np.array(img).reshape(len(img), 1))\n",
    "        return (img[-1])\n",
    "    \n",
    "    def vals_for_softmax(self, index: int) -> np.array:\n",
    "        \"\"\" Helper function to create softmax values\"\"\"\n",
    "        vals = np.zeros(46)\n",
    "        vals[index] = 1\n",
    "        vals.reshape(46, 1)\n",
    "        return vals\n",
    "    \n",
    "    def validate(self, test_df: pd.DataFrame) -> None:\n",
    "        count, countright = 0, 0\n",
    "        for img_dir, row in test_df.iterrows():\n",
    "            img = np.array(Image.open(img_dir).convert(\"L\").resize((32, 32))).flatten().reshape(1024, 1)\n",
    "            outputs = self.pred(img)\n",
    "            actual = self.vals_for_softmax(row[0])\n",
    "            if (outputs.argmax() - actual.argmax() == 0):\n",
    "                countright += 1\n",
    "            count += 1\n",
    "            accuracy = (float(countright) / float(count)) * 100\n",
    "        print(\"count: \", count, \". Countright: \", countright, \" Accuracy: \", accuracy, \"%\")\n",
    "\n",
    "    def save(self) -> None:\n",
    "        hp_data = '/Users/advaysingh/Documents/projects/hindi_classification/data/hyper_p'\n",
    "        hp_data_biases, hp_data_weights = hp_data + '/Biases', hp_data + '/Weights'\n",
    "        os.makedirs(hp_data)\n",
    "        os.makedirs(hp_data_biases)\n",
    "        os.makedirs(hp_data_weights)\n",
    "        for layer in range(len(self.layers)):\n",
    "            df_weights = pd.DataFrame(self.all_weights[layer])\n",
    "            df_bias = pd.DataFrame(self.all_bias[layer])\n",
    "            weights_file_name = \"layer_\" + str(layer) + \"weights.csv\"\n",
    "            bias_file_name = \"layer_\" + str(layer) + \"bias.csv\"\n",
    "            weights_file = open(os.path.join(hp_data_weights, weights_file_name), \"x\")\n",
    "            bias_file = open(os.path.join(hp_data_biases, bias_file_name), \"x\")\n",
    "            df_weights.to_csv(weights_file, index=False)\n",
    "            df_bias.to_csv(bias_file, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vals_for_softmax(index: int) -> np.array:\n",
    "        \"\"\" Helper function to create softmax values\"\"\"\n",
    "        vals = np.zeros(46)\n",
    "        vals[index] = 1\n",
    "        vals.reshape(46, 1)\n",
    "        return vals\n",
    "test_df_sample = test_df.sample(500)\n",
    "\n",
    "\n",
    "X_train, y_train = [], []\n",
    "for img_dir, row in train_df.iterrows():\n",
    "            X_train.append(np.array(Image.open(img_dir)).flatten().reshape(1024, 1))\n",
    "            y_train.append(vals_for_softmax(row[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, mean squared loss: 0.1008997810717031\n",
      "Epoch 1, mean squared loss: 0.10088992079146705\n",
      "Epoch 2, mean squared loss: 0.10088122402015191\n",
      "Epoch 3, mean squared loss: 0.10087904202445673\n",
      "Epoch 4, mean squared loss: 0.10087230011486333\n",
      "Epoch 5, mean squared loss: 0.10086892942108085\n",
      "Epoch 6, mean squared loss: 0.10086229748003699\n",
      "Epoch 7, mean squared loss: 0.10086022353643706\n",
      "Epoch 8, mean squared loss: 0.10085563131693531\n",
      "Epoch 9, mean squared loss: 0.1008519137114579\n",
      "count:  13800 . Countright:  10749  Accuracy:  77.89130434782608 %\n",
      "Epoch 10, mean squared loss: 0.10084801799422545\n",
      "Epoch 11, mean squared loss: 0.10084390699967977\n",
      "Epoch 12, mean squared loss: 0.10084229290853444\n",
      "Epoch 13, mean squared loss: 0.10083575693980028\n",
      "Epoch 14, mean squared loss: 0.10082885111734141\n",
      "Epoch 15, mean squared loss: 0.10082644575775479\n",
      "Epoch 16, mean squared loss: 0.10082196562514287\n",
      "Epoch 17, mean squared loss: 0.10081506466347098\n",
      "Epoch 18, mean squared loss: 0.10081175390487643\n",
      "Epoch 19, mean squared loss: 0.10080781983144957\n",
      "count:  13800 . Countright:  10750  Accuracy:  77.89855072463769 %\n",
      "Epoch 20, mean squared loss: 0.10080677995705489\n",
      "Epoch 21, mean squared loss: 0.10080333335425753\n",
      "Epoch 22, mean squared loss: 0.10079646497462653\n",
      "Epoch 23, mean squared loss: 0.10079277629363101\n",
      "Epoch 24, mean squared loss: 0.10078964617505945\n",
      "Epoch 25, mean squared loss: 0.10078435543201957\n",
      "Epoch 26, mean squared loss: 0.10077746578857515\n",
      "Epoch 27, mean squared loss: 0.10077197979569548\n",
      "Epoch 28, mean squared loss: 0.10076836668036557\n",
      "Epoch 29, mean squared loss: 0.10076501906273032\n",
      "count:  13800 . Countright:  10749  Accuracy:  77.89130434782608 %\n",
      "Epoch 30, mean squared loss: 0.10076026822812238\n",
      "Epoch 31, mean squared loss: 0.10075944405522268\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1066], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cnn \u001b[38;5;241m=\u001b[39m Model([\u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m46\u001b[39m], \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1061], line 136\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, X_train, y_train, epochs, learning_rate, mini_batch_size, test_df)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Update the model's weights with each mini-batch\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mini_batch \u001b[38;5;129;01min\u001b[39;00m mini_batches:\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_mini_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmini_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate(test_df)\n",
      "Cell \u001b[0;32mIn[1061], line 108\u001b[0m, in \u001b[0;36mModel.update_mini_batch\u001b[0;34m(self, mini_batch, learning_rate)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_mini_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, mini_batch, learning_rate):\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# aggregate gradients from the mini_batch\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     delta_w, delta_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprop_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmini_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmini_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m# update weights and biases\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_weights \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;241m-\u001b[39m (learning_rate \u001b[38;5;241m*\u001b[39m dw) \u001b[38;5;28;01mfor\u001b[39;00m w, dw \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_weights, delta_w)] \u001b[38;5;66;03m# todo change\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1061], line 83\u001b[0m, in \u001b[0;36mModel.prop_backward\u001b[0;34m(self, x_batch, y_batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Loop over each example in the batch\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x_batch, y_batch):\n\u001b[0;32m---> 83\u001b[0m     activations, zs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprop_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     delta \u001b[38;5;241m=\u001b[39m (activations[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m y\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m46\u001b[39m,\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m#* softmax_prime(zs[-1])\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# Gradients for output layer\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1061], line 65\u001b[0m, in \u001b[0;36mModel.prop_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m zs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers)):\n\u001b[0;32m---> 65\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_weights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_bias[i]\n\u001b[1;32m     66\u001b[0m     zs\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "cnn = Model([300, 100, 46], True)\n",
    "cnn.train(X_train, y_train, 5000, 0.1, 10000, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:  500 . Countright:  438  Accuracy:  87.6 %\n"
     ]
    }
   ],
   "source": [
    "df_sample = train_df.sample(500)\n",
    "cnn = Model([300, 100, 46], True)\n",
    "cnn.validate(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAgACABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+vXvh18HIdf0X/hIfEt61hpTAtEqsqM6jqxY8Kv8AOti9+DfhHxHazv4F8TJPeQAk28syyBse4AI+uCK8PurWayu5rW4QxzQuY5EPVWBwRU9hpGpao+2wsLq6bOMQxM/P4Cum8Q674q/4RXTfC2sWFza29ixMPmxPGzjsDng47V3fwc8O3nhOS88b+IS+m6XBbMkYm+Vpy3op6jjj1JGK8k8Rar/bniPUtV8sRi7uHmCf3QxJxXt3w5+JfhPQvhfZ6RfarcWGoQNIZfs9vud8ysw2kqQflIGTV2//AGidASSKG20K8vokIzLcsiHjuBg8/lUfimw0742aUt/4Z1+ZdQtY8nSLp9q/Xb2P+1yPpXz7fWN1pt9NZXsDwXMLlJI3GCpHaq9FXtI1e+0LVINS064eC6gbcjqf0PqD6V2/j3xJ4d8c6XBr6uNP8SxqsV3Z+UxW6HADowGAQP7xHAxz3//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAAB8UlEQVR4AWNgoBQwIhvAyC6uKPXl3rNPf5BFEWxWnb473///fXu4SI0NIYpgsTie//cfDP7eLhRDMRqsiMX1OkQaRP6cJYmuglHzKkjm07bOhXd/AlUUodvCXgeU/r7BnZ9VQLP0x///R8UQloNZXLP+/78WwscE5DBK7/3//7UhRAFIAAx+7f35Z/aWT/+AnP+vDzMwcItCHAFX8OfQsvs/WCGKGbkYGD69/A/hwEkmaQtlqMPE9/3/v10ILgNnMEJ9xpH1/f/nCGa4ODqD3e/Z/3/zBZGEGZlZ+eRVxLhZQCawSJc/////iA7McSwMDELGepK6qpwvHxzZ++CXhFu8CfOf3aU3QN6BgjnvQUEIBH9fHVx/+/f//29apGH6wUpAMfTq1K0/YEVAYo8TN0wvkAZaAbT5Yp+QkyzM2b+/oyUHoKb3H8Haf3/98BfIeF4vh7ACqP030BQGhl8frx899+CfU6ghK8O/QzVnfiKsKTzz5v7Oel9NAaA3mThk8h4BDXmUyINQwCapJc8LDgOwGJvp0i///38o50OoQGMxCoTf+f//czY7mjgSl8X88v//T00QLkWSgzCZzS/+/79OAkMcIcDidPP/z3xOhAAGi83n7v9HHugJF1kZu8PJv4f8kUXQ2SzaC369RBckhw8A6+bc6HXpvR4AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted val:\t2. Actual val: \t2\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAgACABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/AOd8B/BSLxd4TtdbutcFn9rZxDCsYY4VymTkjuprmviF8MNU8APBLcTR3djcMVjuIwRhuu1h2OK9P8L/AA2+GfiLwHp9+05iuAiJd3Qu2QicqCyEMdo69hWT4/8Ahx4D8OeAdS1DSNQ+0alG8XkbrwOeZArAKOvyknp/D9a8VW/vFjhRbqYJCCI1DkBMnJx6ckmvSdL8RX/iX4O+KtL1W4e7bTDbXVrJKdzJmQKwyfb+Zp2i6Fqmt/Ar7HpNlNdXM3iLdsiGTtWDk/SvNL20urC8ls7yGSG4hYrJFICCpHYirXh7SH17xFp2kxtta8uEh3Y+6GOCfwHNfT1v4d+GOg+E9StzLbx6dNKtjezvM2ZZYzu2E+ueTiqWs/EXQ/B3w1t7/wAF2UD2hvjZwI6lUJALO3qemMn1ryX4yXUGr6zofiCGAQtq2kw3MqDs+WB+vAA/CuV8E6tb6F430bVLttltbXaPK2CdqZwxwOTgE9K7H4seLvDmq2mmaH4Rffpdu8l1M/lum+Zzz98Akjnn/a9q5/UdesJ/hTouhRXG6+t9Qnnmi2MNqkYU5xg556GsTWdeudah0uKdVVdOs1s4tvdVZjk+/wA1f//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAACX0lEQVR4AaVSz2sTURD+drObNDWpWDX9QaDY9qC0QcUfCFVED9KrGiriSfAP6MGePAiK0KMggiioB/WgKIqiFxUtEsWLsWmtWjTSGBOStM0v0+xu3j7f7K7r4rVzmDcz3zffzL63wGpNEgKycJxzW8p/+hz78HBGVyRsvDB5CQJr29KjsNrCcp0RJZIYAPRKS3QFw+l+Kh2ZLdcqudeTB9ZSNtAQYq5RBT/t1MxMhEXWNa+7sDPWzStjYqA/fr7K9YamNTXdyIF24IsZaU13uwy8G60AgeCboStzQTBF9SeeQQHuPkhJ7bEde2LqzpGngMZl3PwoGiHJTVoBvQFJkgOdwxc1fkPIIPjDGLSAv47IwuTIPT7dJoKOotZnVf530r5mYZ0odpZXov8w0nSMJxfCIRH7FDi3SoCHgEZa6RAlRWE8GFIJFSa+wjUzL9MO7WozemJD4mXNBdzgKtsl4oP891SLLZ3y9hJF8in3W9slX+SWfbWZYavRpQX6u/3bENrcFx+zAERPTph2ZHn18PtCiZuvkovUz3IlxqeDHhy707aw7RP7Dz0xa90egv+2i7M6Z3Gfb6hoxjyEngJnTcExV7J3LvNiF6BO8b1EcJYcXK9dz50JvJj79ikVR2YZaOVtzCEMyImzW9Wl8WzTYCryLdHagO5RiOBtZVROfjFELYwqvQXnVSI4byFBHjmOKeqEijIdZq1EhzOijGNHe43n1isalgL/PlP2EH5hE5BMUUX8pg06HiU1OhyFryviL71Wpwp8sIZ/nrf0nB1yWWD2sX33OorEa1kCFK3S/gCh3iEtHnffqQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted val:\tjha. Actual val: \tjha\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAgACABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/AOU8A3Hwmn0ixsPFOl3R1hnZZboySiJsudv3HGPlKj7vaup8TaF8F9B1240TUrTUdPuoApZ4pJnUhlDAgkt0BHao7L4UfDTW9HvdU0vxbefY7cDzJ5GULAT03bkX+lct4z0D4ZaT4Ulh0DX5L7XoWRw+5mWZS21l4GwYBLevHvXOeCfh1r/jhp5dJWCOC2IEk9xIUUMeQBgEk/hXsHxR+FGp+KvFsOrxalplla/ZI4p5LqYqdy5ycY5GMd6p6jpnh/wz8A/EdpoOqLqTNcxw3V4gwsku+PKr2wFPYnvzXz7XotnPfP8AAW5hsY5dkevBrt4uyGIbd2O27H44q98emK+N7C3Lk+TpUCEZ6HL1LqX/ABKf2bdJgPEmq6o02PVV3DP/AI4v515PXbfDrx8fBt9c299bfbdE1BPLvbXgkjBG5c9+Tx3H4GqXxD8VR+MvGt9rMEbx20m2OBH+8EVQBn3PJ/GtLx14n03VvC/g/RtLmMkemafi5+Rl2ztjcvIGcbeoyOa4Sv/Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAACIElEQVR4AaWSTWgTURDH/283zQdtNmqMhkTUKv2IrYgiSIsXqaAH6cVexIJCjwVB8O5Jr/bmsQiC4EG8iAdPXgRpqa2QEKrFpI1Jkya1bZpmN9nd8W3ebtMNeuocHjP/+b2ZeR/AYY0ByQtWEW392GpuZXchldP07u6CIQXHpran/4AD5Gqi5rfL8aMfls7eSsh4PGPlvpv0P1uFVeHIUOT0xKhcfxC46VVi8TCXWkZrdDJgAZb1PHna6M/KYL7Q9dCdcayU6/OlVzi1INJ8HTHNMSd4RDTl9zGxV7LVYoNddoAwUFU1EsM7QGkTvTbgGwGKDgwH0GsYFL708Ab03D7gsT1Th2I1ZaHJ5x6oOx2Ax9+lwh80pNj4/WHO6fo+YDls9HUqrVEjlV7e5Ve2VKZfARdwpXTgJgvP+oo073QGuMemI9hDgGGzUlj/+jYfDaJgHKzQk6H3g4MfaWtA8cl8gIsGvWzneYVo3HiRRgmVjNbSz0sotAF+di8rfwPzo2kKOQr8cAE1o6KCBdGwP0Y/8NMFVDY2DDAFTfvyE6hlXUB9mYee47A7+AeQ3XIBtDd8CR4FvwURiSHZdAP18LurchfWRIs+H+bsaSyMn4I+4cxsr4K82JYAzbULtLzwItEbk+4JeYaqJzoAXLMeQ0u0ZPkzJb2dALu9Q/RFyIEMzVofw23SRLp6V0jBEk26k62IRYbsF/Yuquf+ARxC+gvDjOPsIsFX+gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted val:\tma. Actual val: \tma\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAgACABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/AOS8IeB/AN34Ot9d8T+LTaTSs4azhkQPHhyoG3DMcgA9OhrWsPA3wh1fUrewsPGGpyXNzII4Y/LILMTgDJiAqK68DfCXT7uaC78cXqvEzI8Qi+ZGU4IOIzzWT49+Gum6XocHiXwnqK32hG3R5jNOplVmcKDtwDjLKMYyDnNeY1seFL4aZ4w0W+YgLb30MjZ9A4J/SvVNd+F+seIPjPqssFh5GjLeJPcXUo2xFSqu+CfvE5PA79cVyXxl0q20r4j3psVRLS8ijuo1j4XDryRjsWBP41yOg6TJr3iDT9IhcRyXlwkAdhkLuIGfwr1TUPEngn4Z6hNpXh/w5Hq+s2b+XLqWoHcokH3tq+xyONv1NM+M/i7WdSi8OtFfSwadqWkRXb20LFVMjE7s4+9jgYNYnxZP2qPwdqQHNz4ftwx9WXOf515/Z3c+n31ve2shjuLeRZY3HVWU5B/MV67Jq3wo8dH+1vEkt9oGsuB9qFqjNHO+OXGEfr74P161yfxO1/Rda1jTbTw48smkaVYR2UEkikGTaSS2CAe46gdKytf8Vtr3h3w9pcloscmjwSQeeGz5qswK8Y4wBiv/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAACK0lEQVR4AaVSTWsTURQ9M5lJmlFaE5PUNtYo0hQr1Gq7UuvHRqVQoaIggiCCiD9AKcWFOymIK93bhS60FRcupJuiC13pShAlDdHUoGmTFM1MW+fj+u5LsJMQN3oWcz/OeffdufcB/wtFFFCCmrHZqRCpLkA2QdGhdvQUPxOTwOCZkWi03cuTp5maZy+sI7g7oCdj+cOF2vXL9BecC9QqcCHXIahwNFUTAbmkWGYXvs6+muUrCnHr062crYSwGh588PjZprWs2/bFnu8FvADEiUPxpaLFZQQSSvKJ6FRAvXZjTTsgXf9nwDM7ZRy7061rWszPST/l0hXpjNFkjVQbNSsmxmSqF+eDkmoSmIuwZL4fe3paCZz3MLjfnaPQBloJkMVeDcapmS5gnxTwYPxYQMRITZzVKbdLzKEFhsl9/kOM/uUUzfEiG6FuvfSC97L++uq26/Sm6QdgjNzLeMy/OxlWcIEW2xqOh07PO3zYpFKaiaNkRv0C465N5Hy4OTxBGZ2JtOv6u1Tve1R+ON6hYL9XlRuIVOmgr0LSpEwfvw9sqdIQ22CWTrCtd5o2vNsf5Z6tMiJM2N/R7xNo+PaIQ0HkkWBLRbSzrVd4uxQ/Xp+LhVUmUIYY9x9BZUafPibFgQiWmRBbHZJNyQBIFag0dSTR2X35l9MncxcpH6qT0oz+JHJL5RWPCmGZiGbmGjapjud4zALTtb6UHbLZjSLK9skKD/tpU35D8Y/eb5qr6dd0HESPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted val:\tka. Actual val: \tma\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAgACABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APEdE8Pat4jvfsej2E15OBuKxL90epPQfjV/TPBms6j4yh8LPbm01KSTYyXHy7MDcSfbAzx1r0nXvgv4a0aeCC78dWmnztbo7RXSAlm5BYfMMKSOK43xJ4D0zR9Fl1LTvGejaqIiu63ifbK2WA+VcnOM5PsDXqvw1sbMfDHQrdNO1SY6rcyfapdOcp8wlZB5rqQVVUw2M84rI+KnhjXNX+LllH4bgujcrYw+ZdRkqIzll3M/b5RXLfHV/wDi4q2gbebSxghJ98Fv/Zq8yr1n4e2Ueg+DLjxZrup6jHpMk/kWul2lw0X22Xp82COOo/A/Q9T8RfEes3vxX0TwhZ3UlvprSWgltoTt3FmBIYjkgDHHSpfiV4q0rwD4uup9M0231DxNflZZri8TettHtCqiD1IX/PSvPfjTaWlv43hmtraO1ku7CG5uYIxgJKwOeOx4Fa/g7xT4PvvBOkaF4svpbFtE1H7XblYHkW4QlmKHaDjlj17Y965bUfHs03xTl8ZwW6yFbrzYYZumxRtUHHfAH41RtPFm/wAcnxPrVkupyGdrhrd5Cqlv4R3+VTjj0GKzfEGu3viXXrvV9QcNc3L7mx0UdAo9gMD8K//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAACiElEQVR4AbVSXUiTYRQ+3zf3fW5u6nTYtjSl3CLTyH5uoi4iIq8SKiS6KSyIKOxHKAovgn6gLoSKLmIkif3cWEaGZSKY2h+LhQMZokkZutjWcn24te373tPZtx9XF13VuTjveZ/znOd933NegH9umgoz91dRh9tZUlpm0ouiwCeJeb+z9Rub62tqS8RISJJj02/fzWbSGkFl8ockzLGEN62gcRxwzDk9DIxHDADoCjOF/RDNpQZdSkDYNUVlngqAJZ8VP05XFZUW6LRCgclKEJl4LCy/uRthhzkQLjzvR5c+VZf1DVLsnN32DO/TNYy2hziaFk4RCGw1jGjuKSLYBRmkKAf+RLY2FbDItHrzcSPtdSPYqcklUDO4T/DduQCgTTbGthJ8LJeQfH70ujSweRXEGXDFLWb4gn8SamLu5mqAQFy/prWRg6+5+WTcq8TnGco41NAjMQmja+lUXXH+4sisV2eD3huD+HMBAxcvo88Kxt097x9sUmelqonlVZV7ZhHnO9YLbThW6OiO07Nm6tSk6vja7giib7uO429h7wYXMu8rGduzEsLOjygr+EgLIPTh8Bh+O2UpforDYlqC3zuP/tZxvEkVeqrGcJMWuLPoUWdCoO1SUfhgBwM/vd9gAS52+nECcAEEtaNEaFyunO8XzBAiQrkZYKArDsBXgI8WCgD2wURn3GpSJmhrzwf2IkqBaQe8zAxNwS4N7MdgJeFHEftIBPJOKKEaWlWFMCiQtxWmArSrhuCZIHVySxt/e1IlkBvCmaVVc3iNTuOvsDsCQcvc+NqSycNxZCfbMbYtCaxosSeXdR8G6xdnUTaKMRmf0H8mS8H5tsLFPHB1k4hTq9X8/3C/AOtqDIU+V1rnAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted val:\tjha. Actual val: \tjha\n"
     ]
    }
   ],
   "source": [
    "sample_imgs = test_df.sample(5)\n",
    "dict = pd.read_csv(os.path.join(workspace, 'data', 'dict.csv'))\n",
    "for img_path, row in sample_imgs.iterrows():\n",
    "    img = Image.open(img_path)\n",
    "    display(img)\n",
    "    img = (np.array(img)).flatten().reshape(1024, 1)\n",
    "    predicted_val = dict.iloc[np.argmax(cnn.pred(img)) - 1, 1]\n",
    "    actual_val = dict.iloc[row[0] - 1, 1]\n",
    "    print('Predicted val:', predicted_val, '. Actual val: ', actual_val, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update stopped by user.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "dict_lib = os.path.join(workspace, 'data/dict.csv')\n",
    "img_path = os.path.join(workspace, 'server/snapshot.png')\n",
    "out_file = os.path.join(workspace, 'server/outputs.json')\n",
    "\n",
    "cnn = Model([300, 100, 46], True)\n",
    "\"\"\"outs = cnn.pred(cnn.img_to_np(img_path))\n",
    "index = outs.index(max(outs))\n",
    "new_english_value = pd.read_csv(os.path.join(workspace, 'data', 'dict.csv'))[index][1]\"\"\"\n",
    "\n",
    "def update_json_file(hindi_value, english_value):\n",
    "    with open(out_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    data['hindi'] = hindi_value\n",
    "    data['english'] = english_value\n",
    "    with open(out_file, 'w') as file:\n",
    "        json.dump(data, file, indent=0)\n",
    "\n",
    "\n",
    "# Updating based on the time\n",
    "try:\n",
    "    while True:\n",
    "        try:\n",
    "            # set img to Image or openCV package (both resulting in lossy conversions).\n",
    "            img = Image.open(img_path).convert('L').resize((32, 32))\n",
    "            #img = cv2.imread(img_path)\n",
    "            #img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            #img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_LANCZOS4) \n",
    "            display(img)\n",
    "            clear_output(wait=True)\n",
    "            img = np.array(img).flatten().reshape(1024, 1)\n",
    "            if np.max(img) == 0:\n",
    "                new_english_value = None; new_hindi_value = None\n",
    "            else: \n",
    "                index = cnn.pred(img).argmax()\n",
    "                new_english_value = str(pd.read_csv(dict_lib).iloc[index - 1, 1])\n",
    "                new_hindi_value = str(pd.read_csv(dict_lib).iloc[index - 1, 2])\n",
    "\n",
    "            update_json_file(new_hindi_value, new_english_value)\n",
    "\n",
    "            \n",
    "        except SyntaxError as e:\n",
    "            print(f\"An error occurred while processing the image: {e}\")\n",
    "            new_english_value = None  # Set a default value or handle differently\n",
    "            new_hindi_value = None\n",
    "        except Exception as e:\n",
    "            # Optionally, catch and handle other non-SyntaxErrors if necessary\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            new_english_value = None  # Set a default value or handle differently\n",
    "            new_hindi_value = None\n",
    "        \n",
    "        # Print the new values (for debug purposes)\n",
    "        # print(f'Updated JSON file with hindi: {new_hindi_value}, english: {new_english_value}')\n",
    "\n",
    "\n",
    "        \n",
    "        time.sleep(0.1)  # Wait for 0.1 seconds (same pace as server.js)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Update stopped by user.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
