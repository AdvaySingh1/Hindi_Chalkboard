{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# import for time, and file change\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "# frequent updating\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define filepaths\n",
    "workspace = \"/Users/advaysingh/Documents/projects/hindi_classification/\" \n",
    "#print(\"Current workspace:\", workspace)\n",
    "\n",
    "data = os.path.join(workspace, 'data/Hindi/')\n",
    "dict_lib = os.path.join(workspace, 'data/dict.csv')\n",
    "img_path = os.path.join(workspace, 'server/snapshot.png')\n",
    "out_file = os.path.join(workspace, 'server/outputs.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test dicts with files and labels\n",
    "\n",
    "def create_dict(x: str) -> dict:\n",
    "    x_dict = {}\n",
    "    i = 0\n",
    "    for dir in os.listdir(os.path.join(data, x)):\n",
    "        for file in os.listdir(os.path.join(data, x, dir)):\n",
    "            x_dict[os.path.join(data, x, dir, file)] = i\n",
    "        i += 1\n",
    "    return x_dict\n",
    "\n",
    "# make pandas df\n",
    "\n",
    "train_df = pd.DataFrame.from_dict(create_dict('Train'), orient='index')\n",
    "test_df = pd.DataFrame.from_dict(create_dict('Test'), orient='index')\n",
    "\n",
    "#print(train_df)\n",
    "#df_temp = train_df[0].drop_duplicates()\n",
    "# print(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.38905609893065\n",
      "20.085536923187668\n",
      "54.598150033144236\n",
      "[0.09003057317038046, 0.24472847105479767, 0.6652409557748219]\n"
     ]
    }
   ],
   "source": [
    "# Activations class\n",
    "class Activation:\n",
    "    # can add more types\n",
    "    def __init__(self, act_type: str) -> None:\n",
    "        self.act = act_type\n",
    "\n",
    "    def print_act(self) -> None:\n",
    "        return self.act\n",
    "    \n",
    "    def compute(self, z):\n",
    "\n",
    "        # Sigmoid function\n",
    "        if (self.act == 'sigmoid'):\n",
    "            n = []\n",
    "            for val in z:\n",
    "                n.append(1 / (1 + math.exp(val)))\n",
    "            return n\n",
    "        \n",
    "        # ReLU function\n",
    "        elif (self.act == 'relu'):\n",
    "            return np.maximum(0, z)\n",
    "\n",
    "    def prime(self, z: list):\n",
    "\n",
    "        # Sigmoid prime\n",
    "        if (self.act == 'sigmoid'):\n",
    "            return (self.compute(z)) * (1 - self.compute(z))\n",
    "        \n",
    "        # ReLU prime\n",
    "        if (self.act == 'relu'):\n",
    "            return int(z > 0)\n",
    "\n",
    "\n",
    "def softmax(costs: list) -> list:\n",
    "    exp_vals = []\n",
    "    for cost in costs:\n",
    "        print(math.exp(cost))\n",
    "        exp_vals.append(math.exp(cost))\n",
    "    return_vals = []\n",
    "    for i in range(len(exp_vals)):\n",
    "        return_vals.append(exp_vals[i] / sum(exp_vals))\n",
    "    return return_vals\n",
    "\n",
    "def softmax_prime(costs: list) -> list:\n",
    "    return softmax(costs) * (1 - softmax(costs))\n",
    "\n",
    "n = softmax([2, 3, 4])\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model:\n",
    "    def __init__(self, train_df: pd.DataFrame,\n",
    "                  act: Activation, layers: list, step: float, stochastic: bool, load_perams: bool) -> None:\n",
    "        self.train_df = train_df\n",
    "\n",
    "        # create activation function\n",
    "        self.act = act\n",
    "        self.layers = layers\n",
    "\n",
    "        # init weight and bias with # layers np arrays\n",
    "        self.all_weights = [None] * (int(len(layers)))\n",
    "        self.all_bias = [None] * (int(len(layers)))\n",
    "        if (load_perams):\n",
    "            layer = 0\n",
    "            weightlist = os.listdir(os.path.join(workspace, 'data', 'Hyper_p/Weights'))\n",
    "            for file in sorted(weightlist, key=lambda s: s.lower()):\n",
    "                self.all_weights[layer] = pd.read_csv(os.path.join(workspace, 'data', 'Hyper_p/Weights', file)).to_numpy()\n",
    "                #self.all_weights[layer] = np.delete(self.all_weights, [0], axis=1)\n",
    "                print(self.all_weights[layer].shape)\n",
    "                layer += 1\n",
    "            layer = 0\n",
    "            biaslist = os.listdir(os.path.join(workspace, 'data', 'Hyper_p/Biases'))\n",
    "            for file in sorted(biaslist, key=lambda s: s.lower()):\n",
    "                self.all_bias[layer] = pd.read_csv(os.path.join(workspace, 'data', 'Hyper_p/Biases', file)).to_numpy()\n",
    "                layer += 1\n",
    "            print(self.all_weights[0])\n",
    "        else:\n",
    "            for i in range(len(layers)):\n",
    "                self.all_weights[i] = self.random_arrs(i)\n",
    "                if i == 0:\n",
    "                    self.all_bias[i] = np.random.uniform(low=-0.03125, high=0.03125, size=(self.layers[i],1))\n",
    "                else:\n",
    "                    bias_val = 1 / math.sqrt(self.layers[layer - 1])\n",
    "                    self.all_bias[i] = np.random.uniform(low=-bias_val, high=bias_val, size=(self.layers[i],1))\n",
    "            #for val in self.all_weights:\n",
    "               # print(val.shape)\n",
    "\n",
    "        # init learn speed\n",
    "        self.speed = step\n",
    "\n",
    "        # determine gradient decent type\n",
    "        self.stochastic = stochastic\n",
    "\n",
    "    def random_arrs(self, layer: int):\n",
    "        if (layer == 0):\n",
    "            return(np.random.uniform(low=-0.03125, high=0.03125, size=(self.layers[layer],1024)))\n",
    "        else:\n",
    "            #return(np.random.uniform(low=-0.03125, high=0.03125, size=(self.layers[layer], self.layers[layer-1])))\n",
    "            weight_val = 1 / math.sqrt(self.layers[layer - 1])\n",
    "            return(np.random.uniform(low=-weight_val, high=weight_val, size=(self.layers[layer], self.layers[layer-1])))\n",
    "\n",
    "    def img_to_np(self, dir) -> np.array:\n",
    "        return np.array(Image.open(dir)).flatten()\n",
    "\n",
    "\n",
    "    def print_weights(self) -> None:\n",
    "        for arr in self.all_weights:\n",
    "            print(arr.shape)\n",
    "\n",
    "    def prop_forward(self, inputs: list, layer: int) -> list:\n",
    "        a_vals = [0.0] * int(self.layers[layer])\n",
    "        a_vals = np.dot(self.all_weights[layer], pd.DataFrame(inputs)) + self.all_bias[layer]\n",
    "        if (layer == len(self.layers) - 1):\n",
    "            return (softmax(a_vals))\n",
    "        return(self.act.compute(a_vals))\n",
    "    \n",
    "\n",
    "\n",
    "    def prop_backword(self, x: list, label: int, layer: int):\n",
    "        outputs = self.prop_forward(x, layer)\n",
    "        if (layer == len(self.layers) - 1):\n",
    "            y = self.vals_for_softmax(label)\n",
    "            for i in range(len(y) - 1):\n",
    "                val = (y[i] - outputs[i]) * softmax_prime(i, outputs) \n",
    "                for j in range(len(x) - 1):\n",
    "                    self.all_weights[layer][i][j] += val* x[j]\n",
    "                    self.all_bias[layer][i][j] += val\n",
    "                return(val)\n",
    "\n",
    "        for output in range(len(outputs)):\n",
    "            val = float(self.prop_backword(outputs, label, layer + 1)) * float(sum(self.all_weights[layer][output]))\n",
    "            for input in range(len(x) - 1):\n",
    "                val += self.act.prime(x[input]) #edit\n",
    "                self.all_weights[layer][output][input] += val * x[input]\n",
    "                self.all_bias[layer][output][input] += val\n",
    "            return val\n",
    "\n",
    "\n",
    "    # potentially reconsider for time complexity\n",
    "    def vals_for_softmax(self, index: int) -> list:\n",
    "        vals = self.train_df[0].unique()\n",
    "        for i in range(len(vals)):\n",
    "            if vals[i] != index:\n",
    "                vals[i] = 0\n",
    "            else:\n",
    "                vals[i] = 1\n",
    "        return vals\n",
    "\n",
    "\n",
    "    def train(self, epochs: int) -> None:\n",
    "        # call back prop with dataset epochs times\n",
    "        for epoch in  range(epochs):\n",
    "            for img_dir, row in self.train_df.iterrows():\n",
    "                self.prop_backword(self.img_to_np(img_dir).tolist(), row[0], 0)\n",
    "            print(\"epoch: \", epoch, self.validate(train_df))\n",
    "\n",
    "    def pred(self, img: np.array) -> int:\n",
    "        for i in range(len(self.layers)):\n",
    "            img = self.prop_forward(img, i)\n",
    "        return img\n",
    "\n",
    "    def validate(self, test_df: pd.DataFrame) -> None:\n",
    "        count, countright = 0, 0\n",
    "        for img_dir, row in test_df.iterrows():\n",
    "            outputs = self.pred(self.img_to_np(img_dir))\n",
    "            actual = list(self.vals_for_softmax(row[0]))\n",
    "            if (outputs.index(max(outputs))) == (actual.index(max(actual))):\n",
    "                countright += 1\n",
    "            count += 1\n",
    "        print(\"count: \", count, \"countright: \", countright)\n",
    "\n",
    "    def save(self) -> None:\n",
    "        hp_data = '/Users/advaysingh/Documents/projects/hindi_classification/data/hyper_p'\n",
    "        hp_data_biases, hp_data_weights = hp_data + '/Biases', hp_data + '/Weights'\n",
    "        os.makedirs(hp_data)\n",
    "        os.makedirs(hp_data_biases)\n",
    "        os.makedirs(hp_data_weights)\n",
    "        for layer in range(len(self.layers)):\n",
    "            df_weights = pd.DataFrame(self.all_weights[layer])\n",
    "            df_bias = pd.DataFrame(self.all_bias[layer])\n",
    "            weights_file_name = \"layer_\" + str(layer) + \"weights.csv\"\n",
    "            bias_file_name = \"layer_\" + str(layer) + \"bias.csv\"\n",
    "            weights_file = open(os.path.join(hp_data_weights, weights_file_name), \"x\")\n",
    "            bias_file = open(os.path.join(hp_data_biases, bias_file_name), \"x\")\n",
    "            df_weights.to_csv(weights_file, index=False)\n",
    "            df_bias.to_csv(bias_file, index=False)\n",
    "\n",
    "\n",
    "    \"\"\"def print_weights(self, layer: int) -> None:\n",
    "        for row in self.all_weights[layer]:\n",
    "            for weight in row:\n",
    "                print(weight)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1024)\n",
      "(46, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/c2gt634j3jd1_cgnqpmpswhw0000gn/T/ipykernel_81072/950884148.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  n.append(1 / (1 + math.exp(val)))\n"
     ]
    }
   ],
   "source": [
    "cnn = Model(train_df, Activation('sigmoid'), [5, 46], 1.2, False, False)\n",
    "cnn.print_weights()\n",
    "cnn.prop_forward([3] * 1024, 0)\n",
    "cnn.save()\n",
    "#cnn.print_weights(1)\n",
    "#cnn.validate(test_df)\n",
    "#cnn.train(1) # something for committing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict = open(os.path.join(data, 'dict.csv'), \"x\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1024)\n",
      "(46, 5)\n",
      "[[0.13867084 0.00595203 0.84538799 ... 0.16139284 0.07455903 0.68609528]\n",
      " [0.47035962 0.93018672 0.20685471 ... 0.39655035 0.54848046 0.29436777]\n",
      " [0.84542472 0.81282378 0.35524723 ... 0.92808459 0.27871833 0.35993218]\n",
      " [0.55314791 0.50851145 0.15798064 ... 0.978258   0.65857135 0.43516438]\n",
      " [0.51129215 0.66847693 0.24802133 ... 0.86948478 0.90842828 0.5043761 ]]\n",
      "4.806359059720454\n",
      "1.9927204874541318\n",
      "3.056150994231626\n",
      "1.969403031284487\n",
      "7.991853783471584\n",
      "7.702991264695115\n",
      "6.147757756773159\n",
      "4.330069420450055\n",
      "4.3223139801812485\n",
      "4.653181189186932\n",
      "4.372100910134904\n",
      "5.264311200049357\n",
      "4.27946577096913\n",
      "5.339943948393503\n",
      "6.2519441986701105\n",
      "7.56205486872587\n",
      "3.867131239858871\n",
      "2.1495707086092444\n",
      "3.1738733973930064\n",
      "2.5674161467457686\n",
      "5.530193553419669\n",
      "3.490622193144374\n",
      "2.1550618511655215\n",
      "4.499859604811533\n",
      "4.915958746109226\n",
      "6.104691156045543\n",
      "3.1692962654628953\n",
      "1.6790756204096728\n",
      "5.613115928448037\n",
      "2.7187267833250957\n",
      "2.3632618594338304\n",
      "3.796636642516107\n",
      "3.600634975171241\n",
      "5.114430130943416\n",
      "5.1928458850295955\n",
      "3.2201748187128736\n",
      "3.3232880730464878\n",
      "5.328715004965953\n",
      "3.2592668945221392\n",
      "4.121431150746743\n",
      "6.132511171914098\n",
      "5.682223161213381\n",
      "2.8714961518753865\n",
      "4.807102135376847\n",
      "3.1954113995568814\n",
      "6.729234441796646\n",
      "4.806359059720454\n",
      "1.9927204874541318\n",
      "3.056150994231626\n",
      "1.969403031284487\n",
      "7.991853783471584\n",
      "7.702991264695115\n",
      "6.147757756773159\n",
      "4.330069420450055\n",
      "4.3223139801812485\n",
      "4.653181189186932\n",
      "4.372100910134904\n",
      "5.264311200049357\n",
      "4.27946577096913\n",
      "5.339943948393503\n",
      "6.2519441986701105\n",
      "7.56205486872587\n",
      "3.867131239858871\n",
      "2.1495707086092444\n",
      "3.1738733973930064\n",
      "2.5674161467457686\n",
      "5.530193553419669\n",
      "3.490622193144374\n",
      "2.1550618511655215\n",
      "4.499859604811533\n",
      "4.915958746109226\n",
      "6.104691156045543\n",
      "3.1692962654628953\n",
      "1.6790756204096728\n",
      "5.613115928448037\n",
      "2.7187267833250957\n",
      "2.3632618594338304\n",
      "3.796636642516107\n",
      "3.600634975171241\n",
      "5.114430130943416\n",
      "5.1928458850295955\n",
      "3.2201748187128736\n",
      "3.3232880730464878\n",
      "5.328715004965953\n",
      "3.2592668945221392\n",
      "4.121431150746743\n",
      "6.132511171914098\n",
      "5.682223161213381\n",
      "2.8714961518753865\n",
      "4.807102135376847\n",
      "3.1954113995568814\n",
      "6.729234441796646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/c2gt634j3jd1_cgnqpmpswhw0000gn/T/ipykernel_81072/950884148.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  n.append(1 / (1 + math.exp(val)))\n",
      "/var/folders/kd/c2gt634j3jd1_cgnqpmpswhw0000gn/T/ipykernel_81072/950884148.py:37: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(math.exp(cost))\n",
      "/var/folders/kd/c2gt634j3jd1_cgnqpmpswhw0000gn/T/ipykernel_81072/950884148.py:38: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  exp_vals.append(math.exp(cost))\n",
      "/var/folders/kd/c2gt634j3jd1_cgnqpmpswhw0000gn/T/ipykernel_81072/950884148.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  n.append(1 / (1 + math.exp(val)))\n",
      "/var/folders/kd/c2gt634j3jd1_cgnqpmpswhw0000gn/T/ipykernel_81072/950884148.py:37: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(math.exp(cost))\n",
      "/var/folders/kd/c2gt634j3jd1_cgnqpmpswhw0000gn/T/ipykernel_81072/950884148.py:38: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  exp_vals.append(math.exp(cost))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.573044265734034\n",
      "1.0486027792648842\n",
      "1.5838599989366875\n",
      "1.1592791812437373\n",
      "2.5144446304022603\n",
      "2.461425435279481\n",
      "2.144832370509424\n",
      "1.4736056385528256\n",
      "1.7699573803056114\n",
      "1.5432091526085616\n",
      "1.4411713337163943\n",
      "2.287997519063537\n",
      "1.5353074206030755\n",
      "2.578163399310738\n",
      "2.451090200452225\n",
      "2.5806659049549325\n",
      "1.4222633356639025\n",
      "1.0767905917119702\n",
      "1.0378201870286503\n",
      "1.3254902206603383\n",
      "2.0902876231909318\n",
      "1.745049427442965\n",
      "1.0139222492409876\n",
      "1.5349860481678845\n",
      "2.5102254147131746\n",
      "1.746623011208863\n",
      "1.1402802624230917\n",
      "1.0979892562600582\n",
      "1.6164356262411954\n",
      "1.1736866799786805\n",
      "1.0290960744957862\n",
      "2.260102321045\n",
      "1.5667489501154157\n",
      "2.0812589943606596\n",
      "1.8814331804445916\n",
      "1.2900028651996003\n",
      "1.0809333659663083\n",
      "1.7039074212384637\n",
      "1.5715118402630022\n",
      "1.6161528373804297\n",
      "1.9718958149503667\n",
      "2.4649840431715853\n",
      "1.0304314325398418\n",
      "1.8163776607373634\n",
      "1.1841030248440265\n",
      "2.2293779080996305\n",
      "2.573044265734034\n",
      "1.0486027792648842\n",
      "1.5838599989366875\n",
      "1.1592791812437373\n",
      "2.5144446304022603\n",
      "2.461425435279481\n",
      "2.144832370509424\n",
      "1.4736056385528256\n",
      "1.7699573803056114\n",
      "1.5432091526085616\n",
      "1.4411713337163943\n",
      "2.287997519063537\n",
      "1.5353074206030755\n",
      "2.578163399310738\n",
      "2.451090200452225\n",
      "2.5806659049549325\n",
      "1.4222633356639025\n",
      "1.0767905917119702\n",
      "1.0378201870286503\n",
      "1.3254902206603383\n",
      "2.0902876231909318\n",
      "1.745049427442965\n",
      "1.0139222492409876\n",
      "1.5349860481678845\n",
      "2.5102254147131746\n",
      "1.746623011208863\n",
      "1.1402802624230917\n",
      "1.0979892562600582\n",
      "1.6164356262411954\n",
      "1.1736866799786805\n",
      "1.0290960744957862\n",
      "2.260102321045\n",
      "1.5667489501154157\n",
      "2.0812589943606596\n",
      "1.8814331804445916\n",
      "1.2900028651996003\n",
      "1.0809333659663083\n",
      "1.7039074212384637\n",
      "1.5715118402630022\n",
      "1.6161528373804297\n",
      "1.9718958149503667\n",
      "2.4649840431715853\n",
      "1.0304314325398418\n",
      "1.8163776607373634\n",
      "1.1841030248440265\n",
      "2.2293779080996305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/c2gt634j3jd1_cgnqpmpswhw0000gn/T/ipykernel_81072/950884148.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  n.append(1 / (1 + math.exp(val)))\n",
      "/var/folders/kd/c2gt634j3jd1_cgnqpmpswhw0000gn/T/ipykernel_81072/950884148.py:37: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(math.exp(cost))\n",
      "/var/folders/kd/c2gt634j3jd1_cgnqpmpswhw0000gn/T/ipykernel_81072/950884148.py:38: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  exp_vals.append(math.exp(cost))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.573044265731372\n",
      "1.0486027792641646\n",
      "1.583859998935726\n",
      "1.1592791812433159\n",
      "2.514444630399244\n",
      "2.4614254352764307\n",
      "2.1448323705075043\n",
      "1.4736056385516156\n",
      "1.7699573803028141\n",
      "1.5432091526065699\n",
      "1.4411713337147345\n",
      "2.2879975190615767\n",
      "1.5353074206009272\n",
      "2.578163399307718\n",
      "2.4510902004518638\n",
      "2.580665904953947\n",
      "1.422263335662239\n",
      "1.0767905917116372\n",
      "1.0378201870272419\n",
      "1.3254902206590784\n",
      "2.090287623187611\n",
      "1.7450494274413706\n",
      "1.0139222492399111\n",
      "1.5349860481661357\n",
      "2.5102254147128322\n",
      "1.746623011207198\n",
      "1.1402802624212893\n",
      "1.097989256259828\n",
      "1.616435626238837\n",
      "1.1736866799771062\n",
      "1.0290960744943405\n",
      "2.260102321044491\n",
      "1.5667489501153264\n",
      "2.081258994359074\n",
      "1.8814331804419184\n",
      "1.2900028651984405\n",
      "1.0809333659650724\n",
      "1.7039074212356247\n",
      "1.5715118402610706\n",
      "1.6161528373800595\n",
      "1.9718958149482\n",
      "2.464984043169432\n",
      "1.0304314325385322\n",
      "1.816377660734668\n",
      "1.184103024843454\n",
      "2.2293779080978737\n",
      "2.573044265731372\n",
      "1.0486027792641646\n",
      "1.583859998935726\n",
      "1.1592791812433159\n",
      "2.514444630399244\n",
      "2.4614254352764307\n",
      "2.1448323705075043\n",
      "1.4736056385516156\n",
      "1.7699573803028141\n",
      "1.5432091526065699\n",
      "1.4411713337147345\n",
      "2.2879975190615767\n",
      "1.5353074206009272\n",
      "2.578163399307718\n",
      "2.4510902004518638\n",
      "2.580665904953947\n",
      "1.422263335662239\n",
      "1.0767905917116372\n",
      "1.0378201870272419\n",
      "1.3254902206590784\n",
      "2.090287623187611\n",
      "1.7450494274413706\n",
      "1.0139222492399111\n",
      "1.5349860481661357\n",
      "2.5102254147128322\n",
      "1.746623011207198\n",
      "1.1402802624212893\n",
      "1.097989256259828\n",
      "1.616435626238837\n",
      "1.1736866799771062\n",
      "1.0290960744943405\n",
      "2.260102321044491\n",
      "1.5667489501153264\n",
      "2.081258994359074\n",
      "1.8814331804419184\n",
      "1.2900028651984405\n",
      "1.0809333659650724\n",
      "1.7039074212356247\n",
      "1.5715118402610706\n",
      "1.6161528373800595\n",
      "1.9718958149482\n",
      "2.464984043169432\n",
      "1.0304314325385322\n",
      "1.816377660734668\n",
      "1.184103024843454\n",
      "2.2293779080978737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/c2gt634j3jd1_cgnqpmpswhw0000gn/T/ipykernel_81072/950884148.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  n.append(1 / (1 + math.exp(val)))\n",
      "/var/folders/kd/c2gt634j3jd1_cgnqpmpswhw0000gn/T/ipykernel_81072/950884148.py:37: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(math.exp(cost))\n",
      "/var/folders/kd/c2gt634j3jd1_cgnqpmpswhw0000gn/T/ipykernel_81072/950884148.py:38: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  exp_vals.append(math.exp(cost))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.573044265731372\n",
      "1.0486027792641646\n",
      "1.583859998935726\n",
      "1.1592791812433159\n",
      "2.514444630399244\n",
      "2.4614254352764307\n",
      "2.1448323705075043\n",
      "1.4736056385516156\n",
      "1.7699573803028141\n",
      "1.5432091526065699\n",
      "1.4411713337147345\n",
      "2.2879975190615767\n",
      "1.5353074206009272\n",
      "2.578163399307718\n",
      "2.4510902004518638\n",
      "2.580665904953947\n",
      "1.422263335662239\n",
      "1.0767905917116372\n",
      "1.0378201870272419\n",
      "1.3254902206590784\n",
      "2.090287623187611\n",
      "1.7450494274413706\n",
      "1.0139222492399111\n",
      "1.5349860481661357\n",
      "2.5102254147128322\n",
      "1.746623011207198\n",
      "1.1402802624212893\n",
      "1.097989256259828\n",
      "1.616435626238837\n",
      "1.1736866799771062\n",
      "1.0290960744943405\n",
      "2.260102321044491\n",
      "1.5667489501153264\n",
      "2.081258994359074\n",
      "1.8814331804419184\n",
      "1.2900028651984405\n",
      "1.0809333659650724\n",
      "1.7039074212356247\n",
      "1.5715118402610706\n",
      "1.6161528373800595\n",
      "1.9718958149482\n",
      "2.464984043169432\n",
      "1.0304314325385322\n",
      "1.816377660734668\n",
      "1.184103024843454\n",
      "2.2293779080978737\n",
      "2.573044265731372\n",
      "1.0486027792641646\n",
      "1.583859998935726\n",
      "1.1592791812433159\n",
      "2.514444630399244\n",
      "2.4614254352764307\n",
      "2.1448323705075043\n",
      "1.4736056385516156\n",
      "1.7699573803028141\n",
      "1.5432091526065699\n",
      "1.4411713337147345\n",
      "2.2879975190615767\n",
      "1.5353074206009272\n",
      "2.578163399307718\n",
      "2.4510902004518638\n",
      "2.580665904953947\n",
      "1.422263335662239\n",
      "1.0767905917116372\n",
      "1.0378201870272419\n",
      "1.3254902206590784\n",
      "2.090287623187611\n",
      "1.7450494274413706\n",
      "1.0139222492399111\n",
      "1.5349860481661357\n",
      "2.5102254147128322\n",
      "1.746623011207198\n",
      "1.1402802624212893\n",
      "1.097989256259828\n",
      "1.616435626238837\n",
      "1.1736866799771062\n",
      "1.0290960744943405\n",
      "2.260102321044491\n",
      "1.5667489501153264\n",
      "2.081258994359074\n",
      "1.8814331804419184\n",
      "1.2900028651984405\n",
      "1.0809333659650724\n",
      "1.7039074212356247\n",
      "1.5715118402610706\n",
      "1.6161528373800595\n",
      "1.9718958149482\n",
      "2.464984043169432\n",
      "1.0304314325385322\n",
      "1.816377660734668\n",
      "1.184103024843454\n",
      "2.2293779080978737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/c2gt634j3jd1_cgnqpmpswhw0000gn/T/ipykernel_81072/950884148.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  n.append(1 / (1 + math.exp(val)))\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "math range error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[256], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#new_english_value = random.choice(english_values)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(img_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)))\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[0;32m---> 31\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpred\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mmax\u001b[39m(cnn\u001b[38;5;241m.\u001b[39mpred(img)))\n\u001b[1;32m     32\u001b[0m new_english_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(workspace, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdict.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39miloc[index, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     34\u001b[0m update_json_file(new_hindi_value, new_english_value)\n",
      "Cell \u001b[0;32mIn[252], line 103\u001b[0m, in \u001b[0;36mModel.pred\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpred\u001b[39m(\u001b[38;5;28mself\u001b[39m, img: np\u001b[38;5;241m.\u001b[39marray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers)):\n\u001b[0;32m--> 103\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprop_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "Cell \u001b[0;32mIn[252], line 59\u001b[0m, in \u001b[0;36mModel.prop_forward\u001b[0;34m(self, inputs, layer)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (layer \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (softmax(a_vals))\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_vals\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[242], line 16\u001b[0m, in \u001b[0;36mActivation.compute\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     14\u001b[0m     n \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m z:\n\u001b[0;32m---> 16\u001b[0m         n\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m n\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# ReLU function\u001b[39;00m\n",
      "\u001b[0;31mOverflowError\u001b[0m: math range error"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "cnn = Model(train_df, Activation('sigmoid'), [5, 46], 1.2, False, True)\n",
    "\"\"\"outs = cnn.pred(cnn.img_to_np(img_path))\n",
    "index = outs.index(max(outs))\n",
    "new_english_value = pd.read_csv(os.path.join(workspace, 'data', 'dict.csv'))[index][1]\"\"\"\n",
    "\n",
    "def update_json_file(hindi_value, english_value):\n",
    "    with open(out_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    data['hindi'] = hindi_value\n",
    "    data['english'] = english_value\n",
    "    with open(out_file, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "# Define a list of possible values if applicable\n",
    "hindi_values = [\"हिं\", \"नया\", \"मूल्य\", \"उदाहरण\"]\n",
    "english_values = [\"Eng\", \"New\", \"Value\", \"Example\"]\n",
    "\n",
    "# Loop to update the JSON file every second with a random value\n",
    "try:\n",
    "    while True:\n",
    "        # Generate a random value from the lists\n",
    "        new_hindi_value = random.choice(hindi_values)\n",
    "        #new_english_value = random.choice(english_values)\n",
    "        img = np.array(Image.open(img_path).convert(\"L\").resize((32, 32))).flatten() * 0.05\n",
    "        index = cnn.pred(img).index(max(cnn.pred(img)))\n",
    "        new_english_value = str(pd.read_csv(os.path.join(workspace, 'data', 'dict.csv')).iloc[index, 1])\n",
    "\n",
    "        update_json_file(new_hindi_value, new_english_value)\n",
    "        \n",
    "        # Print the new values (for debug purposes)\n",
    "        # print(f'Updated JSON file with hindi: {new_hindi_value}, english: {new_english_value}')\n",
    "\n",
    "        # read in and resize img\n",
    " \n",
    "        # read in image for debugging\n",
    "        \"\"\"img.show(\"img to classify\")\n",
    "        print(img.format)\n",
    "        print(img.mode)\n",
    "        print(img.size)\"\"\"\n",
    "\n",
    "        # create np array and resize\n",
    "        \"\"\"img_data = np.array(img).flatten()\n",
    "        print(img_data.shape)\n",
    "        print(img_data)\"\"\"\n",
    "\n",
    "        \n",
    "        time.sleep(10)  # Wait for 1 second\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Update stopped by user.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
